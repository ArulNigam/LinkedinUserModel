{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6979268a",
   "metadata": {},
   "source": [
    "# Machine Learning in Python\n",
    "\n",
    "## Arul Nigam\n",
    "\n",
    "### March 24, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59c93f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502, 89)\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read in data\n",
    "s = pd.read_csv('social_media_usage.csv')\n",
    "\n",
    "# Check the dimensions of the dataframe\n",
    "print(s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d830655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  1\n",
      "1  0  1\n",
      "2  0  1\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def clean_sm(x):\n",
    "    return np.where(x == 1, 1, 0)\n",
    "\n",
    "# toy dataframe\n",
    "toy_df = pd.DataFrame({ \n",
    "    'A': [1, 2, 3],\n",
    "    'B': [1, 1, 1]\n",
    "})\n",
    "\n",
    "# reference: w3schools.com/python/pandas/ref_df_applymap.asp\n",
    "toy_df = toy_df.applymap(clean_sm) \n",
    "print(toy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5553953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             sm_li       income    education       parent      married  \\\n",
      "count  1440.000000  1440.000000  1440.000000  1440.000000  1440.000000   \n",
      "mean      0.322917     6.382639     5.144444     0.236806     0.486111   \n",
      "std       0.467754     2.688374     1.871470     0.425270     0.499981   \n",
      "min       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
      "25%       0.000000     4.000000     3.000000     0.000000     0.000000   \n",
      "50%       0.000000     7.000000     5.000000     0.000000     0.000000   \n",
      "75%       1.000000     9.000000     6.000000     0.000000     1.000000   \n",
      "max       1.000000    10.000000     8.000000     1.000000     1.000000   \n",
      "\n",
      "            female          age  \n",
      "count  1440.000000  1440.000000  \n",
      "mean      0.418750    51.892361  \n",
      "std       0.493526    18.725483  \n",
      "min       0.000000    18.000000  \n",
      "25%       0.000000    36.000000  \n",
      "50%       0.000000    54.000000  \n",
      "75%       1.000000    66.000000  \n",
      "max       1.000000    98.000000  \n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "\n",
    "# redefine clean_sm\n",
    "def clean_sm(x): \n",
    "    return 1 if x == 1 else 0\n",
    "\n",
    "# clean and recode \n",
    "s['sm_li'] = s['web1h'].apply(clean_sm)\n",
    "s['income'] = s['income'].replace([98, 99], np.nan)\n",
    "s['education'] = s['educ2'].replace([98, 99], np.nan)\n",
    "s['parent'] = s['par'].apply(lambda x: 1 if x == 1 else 0)\n",
    "s['married'] = s['marital'].apply(lambda x: 1 if x == 1 else 0)\n",
    "s['female'] = s['gender'].apply(lambda x: 1 if x == 2 else 0)\n",
    "s['age'] = s['age'].where(s['age'] <= 98, np.nan) # traditional .replace doesn't work for open range, so I referenced: note.nkmk.me/en/python-numpy-where/\n",
    "\n",
    "ss = s[['sm_li', 'income', 'education', 'parent', 'married', 'female', 'age']].dropna() # create ss\n",
    "\n",
    "# perform analysis\n",
    "print(ss.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bac1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "y = ss['sm_li']\n",
    "X = ss.drop('sm_li', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0facfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=316203)\n",
    "\n",
    "# X_train: 80% of the dataset, including the features used for training the model.\n",
    "\n",
    "# X_test: 20% of the dataset, including the features used for testing the model.\n",
    "\n",
    "# y_train: X_train's target variable - the outcomes that we will actual use\n",
    "\n",
    "# y_test: X_test's target variable - we will use these coutcomes to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926251b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate logistic model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aee035fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6840277777777778\n",
      "[[130  73]\n",
      " [ 18  67]]\n"
     ]
    }
   ],
   "source": [
    "# Step 7\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# apply the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# output accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# generate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# explanation of my results:\n",
    "\n",
    "# accuracy\n",
    "# proportion of total predictions that were correct\n",
    "# formula: (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "# confusion matrix \n",
    "# 128 = true negatives (correctly predicted that 128 people do not use LinkedIn)\n",
    "# 72 = false positives / Type I error (predicted that 72 people use LinkedIn, but they actually do not)\n",
    "# 22 = false negatives / Type II error (predicted that 22 people do not use LinkedIn, butn they actually do)\n",
    "# 66 = true positives (correctly predicted that 66 people use LinkedIn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8881994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 130                  73\n",
      "Actual Positive                  18                  67\n"
     ]
    }
   ],
   "source": [
    "# Step 8\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, \n",
    "                              index=['Actual Negative', 'Actual Positive'], \n",
    "                              columns=['Predicted Negative', 'Predicted Positive'])\n",
    "print(conf_mat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f08b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74       203\n",
      "           1       0.48      0.79      0.60        85\n",
      "\n",
      "    accuracy                           0.68       288\n",
      "   macro avg       0.68      0.71      0.67       288\n",
      "weighted avg       0.76      0.68      0.70       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 9\n",
    "\n",
    "# precision = TP / (TP + FP) = 66 / (66 + 72) = 0.478 \n",
    "# precision measures how accurate positive predictions are, so high precision indicates a low rate of false positives\n",
    "# this is a valuable metric for detecting spam emails, where there is a high cost to incorrectly classifying a message as spam\n",
    "\n",
    "# recall = TP / (TP + FN) = 66 / (66 + 22) = 0.75\n",
    "# recall measures how well positives are identified. Therefore, high recall indicates a low rate of false negatives\n",
    "# this metric should be employed where there is a high cost to failing to identify positive cases, such as virus tests\n",
    "\n",
    "# f1 = 2 * (precision * recall) / (precision + recall) = 2 * (0.478 * 0.75) / (0.478 + 0.75) = 0.584\n",
    "# the F1 score is the weighted average of precision and recall, accounting for both false positives and false negatives\n",
    "# social media trust & safety teams may employ the f1 score to proeprly identify harmful content but also avoid accidentally flagging posts that are not harmful\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b688c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of LinkedIn use: 0.65\n",
      "Probability of LinkedIn use: 0.37\n",
      "Probability of LinkedIn use: 0.48\n",
      "Probability of LinkedIn use: 0.87\n",
      "Probability of LinkedIn use: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Step 10\n",
    "\n",
    "feature_names = ['income', 'education', 'parent', 'married', 'female', 'age']\n",
    "\n",
    "# profile: high income (e.g. income=8), with a high level of education (e.g. 7), non-parent who is married female and 42 years old uses LinkedIn\n",
    "example1_features = pd.DataFrame([[8, 7, 0, 1, 2, 42]], columns=feature_names) \n",
    "probability_1 = model.predict_proba(example1_features)[0][1]\n",
    "print(f\"Probability of LinkedIn use: {probability_1:.2f}\")\n",
    "\n",
    "# profile: otherwise identical but 82 year old uses LinkedIn\n",
    "example2_features = pd.DataFrame([[8, 7, 0, 1, 2, 82]], columns=feature_names) \n",
    "probability_2 = model.predict_proba(example2_features)[0][1]\n",
    "print(f\"Probability of LinkedIn use: {probability_2:.2f}\")\n",
    "\n",
    "# profile: a top-level income, high school educated, parent who is married, male, and 35 years old\n",
    "example3_features = pd.DataFrame([[9, 3, 1, 1, 1, 35]], columns=feature_names) \n",
    "probability_3 = model.predict_proba(example3_features)[0][1]\n",
    "print(f\"Probability of LinkedIn use: {probability_3:.2f}\")\n",
    "\n",
    "# profile: otherwise identical but postgrad educated person\n",
    "example4_features = pd.DataFrame([[9, 8, 1, 1, 1, 35]], columns=feature_names) \n",
    "probability_4 = model.predict_proba(example4_features)[0][1]\n",
    "print(f\"Probability of LinkedIn use: {probability_4:.2f}\")\n",
    "\n",
    "# profile: $100k income, no formal education, non-parent, never married, female, 49\n",
    "example5_features = pd.DataFrame([[8, 1, 0, 6, 2, 25]], columns=feature_names) \n",
    "probability_5 = model.predict_proba(example5_features)[0][1]\n",
    "print(f\"Probability of LinkedIn use: {probability_5:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
